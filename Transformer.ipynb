{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97aa9f1a",
   "metadata": {},
   "source": [
    "# The Annotated Transformer\n",
    "* * *\n",
    "\n",
    "My implementation based on http://nlp.seas.harvard.edu/annotated-transformer/ . Better said, the code will be almost the same but with my added annotations (with the help of my friend ChatGPT) to understand the transformer architecture on my own way.\n",
    "\n",
    "### Prelims\n",
    "\n",
    "- First install the dependencies from the requirements.txt file in the repo.\n",
    "- Then, install the spacy dependencies using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12bc79e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.2.0/de_core_news_sm-3.2.0-py3-none-any.whl#egg=de_core_news_sm==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting de-core-news-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.2.0/de_core_news_sm-3.2.0-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from de-core-news-sm==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (66.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.1.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.7.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.0.17)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.65.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.28.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.4.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.9)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.4.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (23.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.24.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (6.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.26.15)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.1.2)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.2.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl#egg=en_core_web_sm==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from en-core-web-sm==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.65.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.28.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.24.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (23.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.17)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (66.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.9)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.1.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (6.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.15)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniconda/base/envs/transformer/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.2.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc2c797",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "<div style=\"background-color:#FFFFE0; padding: 20px;\">\n",
    "\n",
    "The following imports are used in the Python code for various purposes:\n",
    "\n",
    "1. `os`: The `os` module provides a way of interacting with the operating system, such as navigating the file system, creating directories, and managing environment variables.\n",
    "2. `os.path.exists`: A function to check if a file or directory exists in the file system.\n",
    "3. `torch`: The main PyTorch library, used for creating and managing tensors, defining neural network layers, and performing various operations on tensors.\n",
    "4. `torch.nn`: A sub-module of PyTorch containing predefined neural network layers and other utilities.\n",
    "5. `torch.nn.functional`: A sub-module of PyTorch containing various activation functions and utility functions, such as padding and normalization.\n",
    "6. `math`: The Python standard library's math module, containing mathematical functions and constants.\n",
    "7. `copy`: The Python standard library's copy module, used for creating shallow and deep copies of Python objects.\n",
    "8. `time`: The Python standard library's time module, used for measuring the execution time of code segments.\n",
    "9. `torch.optim.lr_scheduler`: A sub-module of PyTorch containing various learning rate schedulers for adjusting the learning rate during training.\n",
    "10. `pandas`: A library for data manipulation and analysis, particularly useful for working with tabular data.\n",
    "11. `altair`: A library for declarative data visualization in Python.\n",
    "12. `torchtext.data.functional`: A sub-module of the TorchText library containing utility functions for working with text data.\n",
    "13. `torch.utils.data`: A sub-module of PyTorch containing utilities for working with datasets and data loaders.\n",
    "14. `torchtext.vocab`: A sub-module of the TorchText library containing utilities for building and managing vocabularies.\n",
    "15. `torchtext.datasets`: A sub-module of the TorchText library containing various pre-built datasets for natural language processing tasks.\n",
    "16. `spacy`: A library for natural language processing, used for tokenization, part-of-speech tagging, dependency parsing, and more.\n",
    "17. `GPUtil`: A library for monitoring and managing the GPU utilization and memory usage of NVIDIA GPUs.\n",
    "18. `warnings`: The Python standard library's warnings module, used for managing warning messages during code execution.\n",
    "19. `torch.utils.data.distributed`: A sub-module of PyTorch containing utilities for working with distributed data samplers in multi-GPU or multi-node settings.\n",
    "20. `torch.distributed`: A sub-module of PyTorch containing utilities for distributed training and communication between processes.\n",
    "21. `torch.multiprocessing`: A sub-module of PyTorch providing a PyTorch-specific wrapper around the Python multiprocessing module, used for parallelizing code execution across multiple CPU cores.\n",
    "22. `torch.nn.parallel`: A sub-module of PyTorch containing utilities for parallelizing the training of neural networks across multiple devices.\n",
    "\n",
    "The `warnings.filterwarnings(\"ignore\")` line is used to suppress warning messages during the execution of the notebook. The `RUN_EXAMPLES` variable is set to `True` to enable the execution of examples in the notebook; set it to `False` to skip execution (e.g., for debugging).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb649991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.datasets as datasets\n",
    "import spacy\n",
    "import GPUtil\n",
    "import warnings\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# Set to False to skip notebook execution (e.g. for debugging)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RUN_EXAMPLES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b40b61",
   "metadata": {},
   "source": [
    "### Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2557ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interactive_notebook():\n",
    "    return __name__ == \"__main__\"\n",
    "\n",
    "def show_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        return fn(*args)\n",
    "\n",
    "def execute_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        fn(*args)\n",
    "\n",
    "\n",
    "class DummyOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self):\n",
    "        self.param_groups = [{\"lr\": 0}]\n",
    "        None\n",
    "    \n",
    "    def step(self):\n",
    "        None\n",
    "        \n",
    "    def zero_grad(self, set_to_none=False):\n",
    "        None\n",
    "        \n",
    "\n",
    "class DummyScheduler:\n",
    "    def step(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba209e",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU, ByteNet and ConvS2S, all of which use convolutional neural networks<sup>1</sup> as basic building block, computing hidden representations in parallel for all input and output positions. In these models, the number of operations required to relate signals from two arbitrary input or output positions grows in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes it more difficult to learn dependencies between distant positions. In the Transformer<sup>2</sup> this is reduced to a constant number of operations, albeit at the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention<sup>3</sup>.\n",
    "<div style=\"background-color:#FFFFE0; padding: 20px;\">\n",
    "<sup>1</sup> **Convolutional Neural Networks (CNNs)** are a class of deep learning models that are especially effective in processing grid-like data, such as images. They consist of convolutional layers, which apply filters to local input regions, allowing the model to learn spatial hierarchies and capture local patterns.\n",
    "\n",
    "<sup>2</sup> **Self-Attention** is a mechanism in the Transformer model that allows it to weigh the importance of different input elements when processing a specific element. It computes a score for each pair of elements and uses these scores to create a weighted sum of the input elements, which is then used to compute the output.\n",
    "\n",
    "<sup>3</sup> **Multi-Head Attention** is an extension of the self-attention mechanism in the Transformer model. It uses multiple parallel self-attention layers, or \"heads,\" to focus on different parts of the input simultaneously. This allows the model to capture various aspects of the input data, improving its ability to learn and understand complex dependencies.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752aa7fe",
   "metadata": {},
   "source": [
    "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations. End-to-end memory networks are based on a recurrent attention mechanism instead of sequencealigned recurrence and have been shown to perform well on simple-language question answering and language modeling tasks.  \n",
    "To the best of our knowledge, however, the Transformer is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequence aligned RNNs or convolution.\n",
    "\n",
    "## Part 1: Model Architecture\n",
    "### Model Architecture\n",
    "\n",
    "Most competitive neural sequence transduction models have an encoder-decoder structure<sup>1</sup>. Here, the encoder maps an input sequence of symbol representations $(x_1,...,x_n)$ to a sequence of continuous representations $z = (z_1,...,z_n)$. Given $z$, the decoder then generates an output sequence $(y_1,...,y_m)$ of symbols one element at a time. At each step, the model is auto-regressive<sup>2</sup>, consuming the previously generated symbols as additional input when generating the next.\n",
    "\n",
    "<div style=\"background-color:#FFFFE0; padding: 20px;\">\n",
    "<sup>1</sup> **Encoder-Decoder Architecture**: This structure is commonly used in sequence-to-sequence (seq2seq) models, which are designed to map input sequences to output sequences. The encoder processes the input sequence and generates a continuous representation, often called a \"context vector\" or \"hidden state.\" The decoder then uses this representation to generate the output sequence, step by step. This great <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">reference </a> provides a cool visual explanation.\n",
    "\n",
    "**Example**: Imagine a neural machine translation model that translates English sentences to French. The input sequence consists of English words (e.g., \"How are you?\"), and the output sequence consists of French words (e.g., \"Comment ça va ?\"). In this case, the encoder processes the English words and creates a continuous representation that captures their meaning. The decoder then generates the French translation based on this representation.\n",
    "\n",
    "<sup>2</sup> **Auto-regressive Models**: These models generate output sequences one element at a time, using previously generated elements as additional input for generating the next element. In the context of the encoder-decoder architecture, this means that the decoder generates each output symbol based on the continuous representation from the encoder as well as the previously generated output symbols.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8cb9209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture.\n",
    "    Base for this and many other models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder  # The encoder layer (typically an RNN, CNN, or Transformer)\n",
    "        self.decoder = decoder  # The decoder layer (typically an RNN, CNN, or Transformer)\n",
    "        self.src_embed = src_embed  # The embedding layer for the source language tokens\n",
    "        self.tgt_embed = tgt_embed  # The embedding layer for the target language tokens\n",
    "        self.generator = generator  # The generator layer, which produces the final output (e.g., a linear layer)\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        # Take in and process masked src and target sequences.\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        # Encode the input sequence (src) using the source embedding layer and the encoder.\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        # Decode the encoded memory using the target embedding layer, the decoder, and the masks.\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ac9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Define standard linear + softmax generation step.\n",
    "    The Generator class is responsible for producing the final output\n",
    "    after the Encoder-Decoder architecture processes the input.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)  # Linear layer that maps from the model's hidden dimension to the vocabulary size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply the linear layer and log softmax to produce the output probabilities\n",
    "        return log_softmax(self.proj(x), dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cf4d5",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFFFE0; padding: 20px;\">\n",
    "**log_softmax**: The `log_softmax` function is a combination of the softmax function and the natural logarithm. The softmax function is used to convert a vector of scores into a probability distribution, where each element of the output vector represents the probability of a class in a multi-class classification problem. By applying the natural logarithm to the output of the softmax function, the `log_softmax` function provides more numerically stable results, especially when working with small probabilities or large score values. This stability is particularly useful during optimization, as it helps prevent issues caused by floating-point arithmetic and underflow/overflow errors.\n",
    "\n",
    "In PyTorch, the `log_softmax` function can be found in the `torch.nn.functional` module and is used as follows:\n",
    "\n",
    "```python\n",
    "import torch.nn.functional as F\n",
    "output = F.log_softmax(input_tensor, dim=-1)\n",
    "```\n",
    "Here, input_tensor is the input tensor for which the log_softmax function will be applied, and dim specifies the dimension along which the softmax operation should be computed.\n",
    "</div>\n",
    "\n",
    "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively.\n",
    "\n",
    "<img src=\"fig1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c19e2cb",
   "metadata": {},
   "source": [
    "### Encoder and Decoder Stacks\n",
    "#### Encoder\n",
    "\n",
    "The encoder is composed of a stack of N=6 identical layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e50465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    # Produce N identical layers.\n",
    "    return nn.ModuleList([copy.deepcopy(module)] for _ in range(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22cd0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Core encoder is a stack of N layers.\n",
    "    The Encoder class is a part of the Transformer architecture and\n",
    "    inherits from PyTorch's nn.Module class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)  # Create N clones of the given layer\n",
    "        self.norm = LayerNorm(layer.size)  # Initialize layer normalization for the final output\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # Pass the input (x) and mask through each layer in turn\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)  # Process input and mask through the current layer\n",
    "        return self.norm(x)  # Apply layer normalization to the output after processing all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0ce75",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFFFE0; padding: 20px;\">\n",
    "    \n",
    "Layer normalization is a technique used to improve the training of deep neural networks by normalizing the activations of neurons within each layer. Unlike batch normalization, which normalizes activations across a batch of inputs, layer normalization normalizes activations across the features of a single input.\n",
    "\n",
    "The main idea behind layer normalization is to compute the mean and standard deviation for each input sample and normalize the activations accordingly. After normalization, a learnable scale and shift parameter are applied to the normalized activations. These learnable parameters help the model to adjust the normalization according to the data distribution.\n",
    "\n",
    "Layer normalization has several benefits:\n",
    "\n",
    "1. It reduces the internal covariate shift, making the training process more stable and allowing the use of higher learning rates.\n",
    "2. It allows for faster convergence and, in some cases, better generalization.\n",
    "3. It is less sensitive to the batch size, making it suitable for tasks where the batch size may vary or be small.\n",
    "\n",
    "In PyTorch, layer normalization can be implemented using the `nn.LayerNorm` class. The class constructor takes one required argument, which is the number of features to normalize, and optional arguments for the learnable scale and shift parameters' initial values and a small value for numerical stability (epsilon).\n",
    "\n",
    "Example usage:\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "layer_norm = nn.LayerNorm(num_features)\n",
    "normalized_output = layer_norm(input_tensor)\n",
    "```\n",
    "</div>\n",
    "\n",
    "We employ a residual connection around each of the two sub-layers, followed by layer normalization.\n",
    "\n",
    "<div style=\"background-color:#FFFFE0; padding: 20px;\">\n",
    "    \n",
    "A residual connection, also known as a skip connection or shortcut connection, is an architectural component in deep neural networks that allows the output of a layer to be added to the output of a later layer. This creates a direct path for the gradient to flow during backpropagation, mitigating the vanishing gradient problem and allowing for the training of deeper networks.\n",
    "\n",
    "In the Transformer architecture, residual connections are employed around each of the two sub-layers within the encoder and decoder layers. The output of a sub-layer is added to the input of that sub-layer, and this combined output is then passed through layer normalization. This mechanism helps the model learn more efficiently by allowing the gradients to flow more easily through the network.\n",
    "\n",
    "In PyTorch, a residual connection can be implemented simply by adding the input and output of a layer (or sub-layer) together:\n",
    "\n",
    "```python\n",
    "output = sub_layer(input) + input\n",
    "```\n",
    "    \n",
    "The combined output can then be passed through layer normalization.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5fa9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    # Define a custom LayerNorm class for layer normalization\n",
    "    \n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        # Initialize learnable scale (a_2) and shift (b_2) parameters\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        # Set a small constant value (epsilon) for numerical stability\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Compute the mean and standard deviation of the input tensor along the last dimension\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        # Perform layer normalization: normalize input, then apply learnable scale and shift\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0590f",
   "metadata": {},
   "source": [
    "That is, the output of each sub-layer is LayerNorm(x+Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself. We apply dropout (cite) to the output of each sub-layer, before it is added to the sub-layer input and normalized.\n",
    "\n",
    "To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension d<sub>model</sub> = 512.\n",
    "\n",
    "<div style=\"background-color:#FFFFE0; padding: 20px;\">\n",
    "\n",
    "Dropout is a regularization technique used in training neural networks to prevent overfitting. It is applied during training by randomly setting a fraction of the neurons' activations to zero at each update, effectively \"dropping out\" those neurons from the network. This helps the model to become more robust and generalize better to unseen data.\n",
    "\n",
    "In the Transformer architecture, dropout is applied to the output of each sub-layer before it is added to the sub-layer input and normalized. By adding dropout to the sub-layers, the model becomes more resistant to overfitting, allowing it to learn more complex patterns in the data.\n",
    "\n",
    "In PyTorch, dropout can be applied using the `nn.Dropout` module or the `F.dropout` function from the `torch.nn.functional` module. The dropout probability (i.e., the fraction of neurons to be dropped out) is specified as a hyperparameter when creating the dropout layer or calling the function.\n",
    "\n",
    "For example, to apply dropout with a probability of 0.1, you can use:\n",
    "\n",
    "```python\n",
    "dropout_layer = nn.Dropout(0.1)\n",
    "# or\n",
    "import torch.nn.functional as F\n",
    "output = F.dropout(input, p=0.1, training=True)\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca41dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm. Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        # Apply residual connection to any sublayer with the same size.\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d32ea1",
   "metadata": {},
   "source": [
    "Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward network.\n",
    "\n",
    "<div style=\"background-color:#FFFFE0; padding: 20px;\">\n",
    "\n",
    "**Multi-Head Self-Attention Mechanism**: The multi-head self-attention mechanism allows the model to jointly learn different types of relationships between words in a sequence. It works by first computing a set of attention scores for each word in the sequence with respect to all other words. These scores are then used to weight the input representations, producing a context-aware output representation for each word. The multi-head aspect comes from performing this process multiple times (i.e., using multiple \"heads\") with different learned linear projections, allowing the model to capture different aspects of the relationships between words. Finally, the outputs from all heads are concatenated and projected to produce the final output of the multi-head self-attention layer.\n",
    "\n",
    "**Position-wise Fully Connected Feed-Forward Network**: This is a simple feed-forward network that consists of two linear layers with a ReLU activation function in between. Unlike the multi-head self-attention mechanism, the feed-forward network operates independently on each position (i.e., each word) in the sequence. Its purpose is to provide an additional layer of non-linearity and complexity to the model, allowing it to learn more sophisticated relationships between words in the input sequence.\n",
    "\n",
    "These two sub-layers, combined with the residual connections and layer normalization, form the core building blocks of the Transformer architecture. By stacking multiple such layers, the model can learn increasingly complex patterns and dependencies in the input data, ultimately leading to better performance on a wide range of natural language processing tasks.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a9e0e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    # Define the EncoderLayer class, which is made up of self-attention and feed-forward layers\n",
    "    \n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # Initialize self-attention, feed-forward, and sublayer connection modules\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # Implement the forward pass, following the connections in Figure 1 (left) of the paper\n",
    "        # Apply the self-attention sublayer and pass the output through a SublayerConnection\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        # Apply the feed-forward sublayer and pass the output through another SublayerConnection\n",
    "        return self.sublayer[1](x, self.feed_forward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36908e32",
   "metadata": {},
   "source": [
    "#### Decoder\n",
    "\n",
    "The decoder is also composed of a stack of N = 6 identical layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ab25cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    # Define the Decoder class with N layers and masking capabilities\n",
    "    \n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Initialize the layers by cloning the provided layer N times\n",
    "        self.layers = clones(layer, N)\n",
    "        # Add layer normalization at the end of the processing\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        # Implement the forward pass for the decoder\n",
    "        # Iterate through each layer in the stack\n",
    "        for layer in self.layers:\n",
    "            # Pass the input, memory, source mask, and target mask to the current layer\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        # Apply layer normalization to the final output\n",
    "        return self.norm(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c9edbc",
   "metadata": {},
   "source": [
    "In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c3c6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    # Define the DecoderLayer class, which is made up of self-attention, source-attention, and feed-forward layers\n",
    "    \n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # Initialize size, self-attention, source-attention, feed-forward, and sublayer connection modules\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        # Implement the forward pass for the decoder layer\n",
    "        m = memory\n",
    "        # Apply the self-attention sublayer and pass the output through a SublayerConnection\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        # Apply the source-attention sublayer and pass the output through another SublayerConnection\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        # Apply the feed-forward sublayer and pass the output through the final SublayerConnection\n",
    "        return self.sublayer[2](x, self.feed_forward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0e2d8",
   "metadata": {},
   "source": [
    "We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with the fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i.\n",
    "\n",
    "<div style=\"background-color: lightyellow; padding: 10px;\">\n",
    "For example, let's consider a simple sentence: \"I like ice cream.\" During the decoding process, when predicting the word \"ice,\" we want the decoder to only attend to the words \"I\" and \"like\" (positions before \"ice\") and not the word \"cream\" (a position after \"ice\"). By masking subsequent positions in the self-attention sub-layer, we ensure that the model only considers the words before the current position when making a prediction, thus preventing it from using future information. This is crucial for tasks like translation, where the model needs to generate the target sentence in a left-to-right manner.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10134964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    # Mask out subsequent positions\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
    "    return subsequent_mask==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d318fb",
   "metadata": {},
   "source": [
    "Below the attention mask shows the position each tgt word (row) is allowed to look at (column). Words are blocked for attending to future words during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a524698e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-fd26df60afca43f8b8f57acf672f6fdd\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-fd26df60afca43f8b8f57acf672f6fdd\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-fd26df60afca43f8b8f57acf672f6fdd\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-ac10fa76400c18dafea2d104267bb03d\"}, \"mark\": \"rect\", \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"Subsequent Mask\", \"scale\": {\"scheme\": \"viridis\"}}, \"x\": {\"type\": \"ordinal\", \"field\": \"Window\"}, \"y\": {\"type\": \"ordinal\", \"field\": \"Masking\"}}, \"height\": 250, \"selection\": {\"selector004\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 250, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-ac10fa76400c18dafea2d104267bb03d\": [{\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 0}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 1, \"Masking\": 0}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 2, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 2, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 16}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 18, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 18, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 16}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 17}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 19, \"Masking\": 19}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_mask():\n",
    "    # Combine all masking information into a Pandas DataFrame\n",
    "    LS_data = pd.concat([\n",
    "        pd.DataFrame({\n",
    "            \"Subsequent Mask\": subsequent_mask(20)[0][x, y].flatten(),\n",
    "            \"Window\": y,\n",
    "            \"Masking\": x,\n",
    "        }) for y in range(20) for x in range(20)\n",
    "    ])\n",
    "    \n",
    "    # Create an Altair chart to visualize the subsequent mask\n",
    "    return (\n",
    "        alt.Chart(LS_data)\n",
    "        .mark_rect()  # Use rectangular marks to represent masking values\n",
    "        .properties(height=250, width=250)  # Set chart dimensions\n",
    "        .encode(\n",
    "            alt.X(\"Window:O\"),  # Map the 'Window' column to the X-axis\n",
    "            alt.Y(\"Masking:O\"),  # Map the 'Masking' column to the Y-axis\n",
    "            alt.Color(\"Subsequent Mask:Q\", scale=alt.Scale(scheme=\"viridis\")),  # Map the 'Subsequent Mask' column to the color of the marks\n",
    "        )\n",
    "        .interactive()  # Make the chart interactive (e.g., support zooming and panning)\n",
    "    )\n",
    "\n",
    "# Call the `show_example` function to display the chart\n",
    "show_example(example_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557f45b",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a02cf22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
